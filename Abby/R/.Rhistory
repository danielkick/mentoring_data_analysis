<<<<<<< Updated upstream
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "black")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "firebrick", shape = 1)+
geom_point(aes(x = time_min, y = in6), color = "Blue", shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "firebrick")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "black", shape = 1)+
geom_point(aes(x = time_min, y = in6), color = "Blue", shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "blakc")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "black", shape = 1)+
geom_point(aes(x = time_min, y = in6), color = "Blue", shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "black")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "black", shape = 1)+
geom_point(aes(x = time_min, y = in6), color = "Blue", shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "black")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "black", shape = 1)+
geom_point(aes(x = time_min, y = in6, color = condition), shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "black")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "black", shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
temp <- M[, c("exp",
"time_min",
"condition",
"in4",
"in6")]
temp <- temp %>% gather(channel, voltage, 4:5)
ggplot(temp, aes(x = condition, y = voltage))+
geom_violin()+
facet_grid(channel~exp)
temp, aes(x = condition, fill = condition, y = voltage))+
ggbee
ggplot(temp, aes(x = condition, fill = condition, y = voltage))+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(channel~exp)
ggplot(temp, aes(x = condition, fill = condition, y = voltage))+
geom_violin()
ggplot(temp, aes(x = condition, fill = condition, y = voltage))+
geom_violin()+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(channel~exp)
ggplot(temp, aes(x = condition, fill = condition, y = voltage))+
geom_violin()+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(channel~exp)+
labs(title = "Voltage Across Treatment", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
plts_cor <- list(plt_0, plt_1, plt_2, plt_3)
#TODO remove next line and rerun (or decrease data reduction and rerun)
M <- M[seq(1, nrow(M), by = 100), ]
plt_0 <- ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "black")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "black", shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
temp <- M[, c("exp",
"time_min",
"condition",
"in4",
"in6")]
temp <- temp %>% gather(channel, voltage, 4:5)
plt_1 <- ggplot(temp, aes(x = condition, fill = condition, y = voltage))+
geom_violin()+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(channel~exp)+
labs(title = "Voltage Across Treatment", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
plt_2 <-  ggplot(M, aes_string(x = "condition", y = "cor", fill = "condition", group = "condition"))+
geom_boxplot()+
#geom_violin()+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(.~exp)+
labs(title = "Correlation Across Treatments")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
plt_3 <-  ggplot(M, aes_string(x = "time_min", y = "cor", color = "condition", group = "exp"))+
geom_point(shape = 1)+
#geom_line()+
geom_smooth(color = "black")+
facet_grid(~exp)+
labs(title = "Correlation Across Time")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
plts_cor <- list(plt_0, plt_1, plt_2, plt_3)
#plts_list <- list()
plts_list <- plts_cor
for (i in seq_along(plts_v)){
plts_list[[length(plts_list)+1]] <- plts_v[[i]]
plts_list[[length(plts_list)+1]] <- plts_l[[i]]
}
length(plts_list)
my_pres <- read_pptx("../Out/SlideTemplate.pptx")
my_pres <- my_pres %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with_gg(value = plts_list[[1]] )
print(my_pres, target = "../Out/first_example.pptx")
my_pres <- read_pptx("../Out/SlideTemplate.pptx")
my_pres <- my_pres %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with_gg(value = plt_1 )
print(my_pres, target = "../Out/first_example.pptx")
ggsave("../Out/test.pdf", plot = plts_list[[1]])
plts_list[[1]]
plt_0
ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "black")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "black", shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
ggplot(temp, aes(x = condition, fill = condition, y = voltage))+
geom_violin()+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(channel~exp)+
labs(title = "Voltage Across Treatment", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
plt_1
plt_1
=======
>>>>>>> Stashed changes
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(readr) # write_rds, read_rds
library(esquisse) # GUI interface for ggplot2
library(readxl) # Importing xlsx
library(mgcv) # Used to drop low signal/noise data with GAM
library(janitor) # renaming df names
library(tidyverse) # Plotting, Data wrangling
library(cowplot) # plot grid
<<<<<<< Updated upstream
library(ggbeeswarm)
library(lemon)
library(officer)
update.data.frame <- FALSE
=======
update.data.frame <- TRUE
>>>>>>> Stashed changes
use.cor.bins <- 1000
drop.low.signal.noise <- TRUE
# Chunk 2: custom funcitons
make_list_from_excels <- function(target.dir = "C:/Users/drk8b9/Documents/GitHubRepos/mentoring_data_analysis/Abby/Data/data_dirs/",
reduce.by = 1000) {
tic <- Sys.time()
sub.dirs <- list.files(target.dir)
output.list <- list()
for (i in seq_along(sub.dirs)) {
target.files <- list.files(paste0(target.dir, sub.dirs[i], "/"))
temp.list <- list()
for (j in seq_along(target.files)) {
temp <- readxl::read_xlsx(paste0(target.dir, sub.dirs[i], "/", target.files[j]))
temp <- janitor::clean_names(temp)
# Reduce data by user specified amount
temp <- temp[seq(from = 1, to = nrow(temp), by = reduce.by), ]
#  duplicate the first row of $Condition and $`File Number` for all rows
temp[seq(1, nrow(temp)), "condition"] <- temp[1, "condition"]
temp[seq(1, nrow(temp)), "file_number"] <- temp[1, "file_number"]
# Add a column to help correct time col later
temp$recording <- target.files[j]
temp.list[[(length(temp.list) + 1)]] <- temp
}
output.list[[(length(output.list) + 1)]] <- temp.list
}
toc <- Sys.time()
print(toc - tic)
return(output.list)
}
make_ldf_from_lol <- function(input.list = output.list) {
# Convert list of lists (of dfs) into list of dfs
output.list <- list()
for (i in seq_along(input.list)) {
temp.list <- input.list[[i]]
temp.df <- data.frame()
# Consolidate everything from one exp
for (j in seq_along(temp.list)) {
temp.df <- rbind(temp.df, temp.list[[j]])
}
output.list[[(length(output.list) + 1)]] <- temp.df
}
return(output.list)
}
make_df_from_ldf <- function(
input.list = output.list) {
# Convert a list of dfs into one df
output.df <- data.frame()
for (i in seq_along(input.list)) {
output.df <- rbind(output.df, input.list[[i]])
}
return(output.df)
}
get_cor_over_time <- function(input.df = M[1:100, ],
col.x = "in4",
col.y = "in6",
nbins = 3,
keep.every = 1,
method = "pearson") {
out.vector <- matrix(nrow = nrow(input.df), ncol = 1)
bin.size <- floor(nrow(input.df) / nbins)
bin.start <- 1
for (i in 1:nbins) {
if (i != nbins) {
bin.end <- bin.start + bin.size
} else {
# For the last itteration, lump all the remaining observations into the last bin. This of course can result in the final bin being (2x-1) instead of x.
bin.end <- nrow(input.df)
}
bin.cor <- cor(input.df[seq(from = bin.start, to = bin.end, by = keep.every), col.x],
input.df[seq(from = bin.start, to = bin.end, by = keep.every), col.y],
method = method
)
out.vector[seq(from = bin.start, to = bin.end, by = 1)] <- bin.cor
bin.start <- bin.end
}
return(out.vector)
}
# Chunk 3: read in and condense data
if (update.data.frame == TRUE){
#### Outline ####
# For each dir in Abby/Data/data_dirs/
# For each excel file
# reduce data by a set factor
# return list (of files in exp)
# return list of lists (of returned lists)
<<<<<<< Updated upstream
output.list0 <- make_list_from_excels(target.dir = "//bio-files.col.missouri.edu/schulzlab/Data_Undergraduate/Data_Abby/Fall2018/Excel Sheets/",
=======
output.list0 <- make_list_from_excels(target.dir = "S:/Data_Undergraduate/Data_Abby/Fall2018/data/",
>>>>>>> Stashed changes
reduce.by = 500)
#output.list0 <- make_list_from_excels(target.dir = "C:/Users/drk8b9/Documents/GitHubRepos/mentoring_data_analysis/Abby/Data/data_dirs/",
#                                  reduce.by = 500)
output.list1 <- make_ldf_from_lol(input.list = output.list0)
output.list2 <- make_df_from_ldf(input.list = output.list1)
M <- output.list2
write_rds(M, "../data/combined_data.rds")
write.csv(M, "../data/combined_data.csv")
} else {
M <- read_rds("../data/combined_data.rds")
}
<<<<<<< Updated upstream
# Chunk 4: correct time and lables
=======
# Chunk 4: correct time
>>>>>>> Stashed changes
M$exp <- rep(NA, times = nrow(M))
M$rec <- rep(NA, times = nrow(M))
# correct times for each df
recs <- unique(M$recording)
for (i in seq_along(recs)){
M[M$recording == recs[i], c("exp")] <- stringr::str_split(recs[i], pattern = "_", n = 2)[[1]][1]
M[M$recording == recs[i], c("rec")] <- stringr::str_split(recs[i], pattern = "_", n = 2)[[1]][2]
}
# update times using unique() within each experiment. Add previous largest time, use a placeholder variable.
exps <- unique(M$exp)
for (i in seq_along(exps)){
recs <- M[M$exp == exps[i], "rec"]$rec %>% unique()
offset <- 0
for (j in seq_along(recs)){
if (j == 1){
offset <- M[M$exp == exps[i] & M$rec == recs[j] , "time_ms"] %>% max()
} else {
M[M$exp == exps[i] & M$rec == recs[j] , "time_ms"] <- M[M$exp == exps[i] & M$rec == recs[j] , "time_ms"] + offset
offset <- M[M$exp == exps[i] & M$rec == recs[j] , "time_ms"] %>% max()
}
}
}
<<<<<<< Updated upstream
#correct labels
exp_names <- unique(M$exp)
new_exp_names <- seq(from = 1, to = length(exp_names), by = 1)
for(i in seq_along(exp_names)){
M[M$exp == exp_names[i], "exp"] <- new_exp_names[i]
}
M$exp <- as.factor(M$exp)
=======
# Chunk 5: drop near baseline mv data
if (drop.low.signal.noise == TRUE){
M$in4_threshold <- NA
M$in6_threshold <- NA
exps <- unique(M$exp)
for (i in seq_along(exps)){
exp.time <- M[M$exp == exps[i], "time_ms"]
fm.1 <- mgcv::gam(in4 ~ s(time_ms, bs = "cs"),
data = M[M$exp == exps[i],])
fm.2 <- mgcv::gam(in6 ~ s(time_ms, bs = "cs"),
data = M[M$exp == exps[i],])
M[M$exp == exps[i], "in4_threshold"] <- predict(fm.1, exp.time)
M[M$exp == exps[i], "in6_threshold"] <- predict(fm.2, exp.time)
}
M[(M$in4 <= M$in4_threshold) | (M$in6 <= M$in6_threshold), c("in4", "in6")] <- NA
M <- M[, !(names(M) %in% c("in4_threshold", "in6_threshold"))]
M <- M[!(is.na(M$in4)),]
}
# Chunk 6: produce correlation coefficients
M$cor <- NA
exps <- unique(M$exp)
for (i in seq_along(exps)){
temp <- M[M$exp == exps[i], ]
out <- get_cor_over_time(input.df = temp,
col.x = "in4",
col.y = "in6",
nbins = use.cor.bins,
keep.every = 1,
method = "pearson")
M[M$exp == exps[i], "cor"] <- out
}
install.packages("readr") # write_rds, read_rds
install.packages("esquisse") # GUI interface for ggplot2
install.packages("readxl") # Importing xlsx
install.packages("mgcv") # Used to drop low signal/noise data with GAM
install.packages("janitor") # renaming df names
install.packages("tidyverse") # Plotting, Data wrangling
install.packages("mgcv")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(readr) # write_rds, read_rds
library(esquisse) # GUI interface for ggplot2
library(readxl) # Importing xlsx
library(mgcv) # Used to drop low signal/noise data with GAM
library(janitor) # renaming df names
library(tidyverse) # Plotting, Data wrangling
library(cowplot) # plot grid
update.data.frame <- TRUE
use.cor.bins <- 1000
drop.low.signal.noise <- TRUE
# Chunk 2: custom funcitons
make_list_from_excels <- function(target.dir = "C:/Users/drk8b9/Documents/GitHubRepos/mentoring_data_analysis/Abby/Data/data_dirs/",
reduce.by = 1000) {
tic <- Sys.time()
sub.dirs <- list.files(target.dir)
output.list <- list()
for (i in seq_along(sub.dirs)) {
target.files <- list.files(paste0(target.dir, sub.dirs[i], "/"))
temp.list <- list()
for (j in seq_along(target.files)) {
temp <- readxl::read_xlsx(paste0(target.dir, sub.dirs[i], "/", target.files[j]))
temp <- janitor::clean_names(temp)
# Reduce data by user specified amount
temp <- temp[seq(from = 1, to = nrow(temp), by = reduce.by), ]
#  duplicate the first row of $Condition and $`File Number` for all rows
temp[seq(1, nrow(temp)), "condition"] <- temp[1, "condition"]
temp[seq(1, nrow(temp)), "file_number"] <- temp[1, "file_number"]
# Add a column to help correct time col later
temp$recording <- target.files[j]
temp.list[[(length(temp.list) + 1)]] <- temp
}
output.list[[(length(output.list) + 1)]] <- temp.list
}
toc <- Sys.time()
print(toc - tic)
return(output.list)
}
make_ldf_from_lol <- function(input.list = output.list) {
# Convert list of lists (of dfs) into list of dfs
output.list <- list()
for (i in seq_along(input.list)) {
temp.list <- input.list[[i]]
temp.df <- data.frame()
# Consolidate everything from one exp
for (j in seq_along(temp.list)) {
temp.df <- rbind(temp.df, temp.list[[j]])
}
output.list[[(length(output.list) + 1)]] <- temp.df
}
return(output.list)
}
make_df_from_ldf <- function(
input.list = output.list) {
# Convert a list of dfs into one df
output.df <- data.frame()
for (i in seq_along(input.list)) {
output.df <- rbind(output.df, input.list[[i]])
}
return(output.df)
}
get_cor_over_time <- function(input.df = M[1:100, ],
col.x = "in4",
col.y = "in6",
nbins = 3,
keep.every = 1,
method = "pearson") {
out.vector <- matrix(nrow = nrow(input.df), ncol = 1)
bin.size <- floor(nrow(input.df) / nbins)
bin.start <- 1
for (i in 1:nbins) {
if (i != nbins) {
bin.end <- bin.start + bin.size
} else {
# For the last itteration, lump all the remaining observations into the last bin. This of course can result in the final bin being (2x-1) instead of x.
bin.end <- nrow(input.df)
}
bin.cor <- cor(input.df[seq(from = bin.start, to = bin.end, by = keep.every), col.x],
input.df[seq(from = bin.start, to = bin.end, by = keep.every), col.y],
method = method
)
out.vector[seq(from = bin.start, to = bin.end, by = 1)] <- bin.cor
bin.start <- bin.end
}
return(out.vector)
}
# Chunk 3: read in and condense data
if (update.data.frame == TRUE){
#### Outline ####
# For each dir in Abby/Data/data_dirs/
# For each excel file
# reduce data by a set factor
# return list (of files in exp)
# return list of lists (of returned lists)
output.list0 <- make_list_from_excels(target.dir = "S:/Data_Undergraduate/Data_Abby/Fall2018/data/",
reduce.by = 500)
#output.list0 <- make_list_from_excels(target.dir = "C:/Users/drk8b9/Documents/GitHubRepos/mentoring_data_analysis/Abby/Data/data_dirs/",
#                                  reduce.by = 500)
output.list1 <- make_ldf_from_lol(input.list = output.list0)
output.list2 <- make_df_from_ldf(input.list = output.list1)
M <- output.list2
write_rds(M, "../data/combined_data.rds")
write.csv(M, "../data/combined_data.csv")
} else {
M <- read_rds("../data/combined_data.rds")
}
# Chunk 4: correct time
M$exp <- rep(NA, times = nrow(M))
M$rec <- rep(NA, times = nrow(M))
# correct times for each df
recs <- unique(M$recording)
for (i in seq_along(recs)){
M[M$recording == recs[i], c("exp")] <- stringr::str_split(recs[i], pattern = "_", n = 2)[[1]][1]
M[M$recording == recs[i], c("rec")] <- stringr::str_split(recs[i], pattern = "_", n = 2)[[1]][2]
}
# update times using unique() within each experiment. Add previous largest time, use a placeholder variable.
exps <- unique(M$exp)
for (i in seq_along(exps)){
recs <- M[M$exp == exps[i], "rec"]$rec %>% unique()
offset <- 0
for (j in seq_along(recs)){
if (j == 1){
offset <- M[M$exp == exps[i] & M$rec == recs[j] , "time_ms"] %>% max()
} else {
M[M$exp == exps[i] & M$rec == recs[j] , "time_ms"] <- M[M$exp == exps[i] & M$rec == recs[j] , "time_ms"] + offset
offset <- M[M$exp == exps[i] & M$rec == recs[j] , "time_ms"] %>% max()
}
}
}
>>>>>>> Stashed changes
# Chunk 5: drop near baseline mv data
if (drop.low.signal.noise == TRUE){
M$in4_threshold <- NA
M$in6_threshold <- NA
exps <- unique(M$exp)
for (i in seq_along(exps)){
exp.time <- M[M$exp == exps[i], "time_ms"]
fm.1 <- mgcv::gam(in4 ~ s(time_ms, bs = "cs"),
data = M[M$exp == exps[i],])
fm.2 <- mgcv::gam(in6 ~ s(time_ms, bs = "cs"),
data = M[M$exp == exps[i],])
M[M$exp == exps[i], "in4_threshold"] <- predict(fm.1, exp.time)
M[M$exp == exps[i], "in6_threshold"] <- predict(fm.2, exp.time)
}
M[(M$in4 <= M$in4_threshold) | (M$in6 <= M$in6_threshold), c("in4", "in6")] <- NA
M <- M[, !(names(M) %in% c("in4_threshold", "in6_threshold"))]
M <- M[!(is.na(M$in4)),]
}
# Chunk 6: produce correlation coefficients
M$cor <- NA
exps <- unique(M$exp)
for (i in seq_along(exps)){
temp <- M[M$exp == exps[i], ]
out <- get_cor_over_time(input.df = temp,
col.x = "in4",
col.y = "in6",
nbins = use.cor.bins,
keep.every = 1,
method = "pearson")
M[M$exp == exps[i], "cor"] <- out
}
<<<<<<< Updated upstream
# Chunk 7: make time col more user friendly
M$time_min <- M$time_ms/60000
# Chunk 8: preliminary plots
p1 <- ggplot(M)+
geom_point(aes(x = time_ms, y = in4, color = condition))+
geom_point(aes(x = time_ms, y = in6, color = condition))+
facet_grid(~exp)
p2 <- ggplot(M, aes(x = time_ms, y = cor, color = condition, group = exp))+
geom_point()+
geom_line()+
facet_grid(~exp)
cowplot::plot_grid(plotlist = list(p1, p2), nrow = 2, ncol =1)
ggplot(M)+
geom_point(aes(x = time_ms, y = in4, color = condition))+
geom_point(aes(x = time_ms, y = in6, color = condition))+
geom_smooth(aes(x = time_ms, y = in4), color = "black")+
geom_smooth(aes(x = time_ms, y = in6), color = "black")+
facet_grid(~exp)
# Chunk 9
#TODO remove next line and rerun (or decrease data reduction and rerun)
M <- M[seq(1, nrow(M), by = 100), ]
plt_0 <- ggplot(M)+
geom_smooth(aes(x = time_min, y = in4), color = "black")+
geom_smooth(aes(x = time_min, y = in6), color = "Blue")+
geom_point(aes(x = time_min, y = in4, color = condition))+
geom_point(aes(x = time_min, y = in6, color = condition))+
geom_point(aes(x = time_min, y = in4), color = "black", shape = 1)+
facet_grid(~exp)+
labs(title = "Voltage Across Time", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
temp <- M[, c("exp",
"time_min",
"condition",
"in4",
"in6")]
temp <- temp %>% gather(channel, voltage, 4:5)
plt_1 <- ggplot(temp, aes(x = condition, fill = condition, y = voltage))+
geom_violin()+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(channel~exp)+
labs(title = "Voltage Across Treatment", y = "Voltage in mV")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
plt_2 <-  ggplot(M, aes_string(x = "condition", y = "cor", fill = "condition", group = "condition"))+
geom_boxplot()+
#geom_violin()+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(.~exp)+
labs(title = "Correlation Across Treatments")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
plt_3 <-  ggplot(M, aes_string(x = "time_min", y = "cor", color = "condition", group = "exp"))+
geom_point(shape = 1)+
#geom_line()+
geom_smooth(color = "black")+
facet_grid(~exp)+
labs(title = "Correlation Across Time")+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
plts_cor <- list(plt_0, plt_1, plt_2, plt_3)
plt_0
burst.stats <- read.csv("//bio-files.col.missouri.edu/schulzlab/Data_Undergraduate/Data_Abby/Fall2018/Extracell_Data/Master_Excell_Sheet/Fall2018_Extracell.csv")
burst.stats <- janitor::clean_names(burst.stats)
burst.stats <- as.tibble(burst.stats)
# convert time to more intuitive unit
burst.stats$time_min <- (burst.stats$start_t_s/60)
# drop redundent cols
burst.stats <- burst.stats[, 6:16]
burst.stats <- burst.stats[, !(names(burst.stats) %in% c("file_number"))]
burst.stats <- rename(burst.stats, exp = experiment)
burst.stats$exp <- as.factor(burst.stats$exp)
# set data types
#TODO remove next line and rerun (or decrease data reduction and rerun)
burst.stats <- burst.stats[seq(1, nrow(burst.stats), by = 10), ]
plts_v <- map(1:7, function(i){
use.cols <- names(burst.stats)
# Violin plots
ggplot(burst.stats, aes_string(x = "condition", y = use.cols[i], fill = "condition", group = "condition"))+
geom_violin()+
ggbeeswarm::geom_beeswarm(color = "black", shape = 1, alpha = 0.6)+
facet_grid(.~exp)+
labs(title = use.cols[i])+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
})
plts_l <- map(1:7, function(i){
use.cols <- names(burst.stats)
# line plots
ggplot(burst.stats, aes_string(x = "time_min", y = use.cols[i], color = "condition", group = "exp"))+
geom_point(shape = 1)+
#geom_line()+
geom_smooth(color = "black")+
facet_grid(~exp)+
labs(title = use.cols[i])+
theme(legend.position = "")+
coord_capped_cart(bottom = "both") +
theme(panel.border = element_blank(), axis.line = element_line()) + # needed for lemon
theme(text = element_text(face = "bold", size = 14))
})
#plts_list <- list()
plts_list <- plts_cor
for (i in seq_along(plts_v)){
plts_list[[length(plts_list)+1]] <- plts_v[[i]]
plts_list[[length(plts_list)+1]] <- plts_l[[i]]
}
ggsave("../Out/test.pdf", plot = plts_list[[1]])
my_pres <- read_pptx("../Out/SlideTemplate.pptx")
my_pres <- my_pres %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with_gg(value = plts_list[[1]] )
print(my_pres, target = "../Out/first_example.pptx")
my_pres <- read_pptx("../Out/SlideTemplate.pptx")
walk(plts_list, function(i){
my_pres <<- my_pres %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with_gg(value = i )
})
print(my_pres, target = "../Out/first_example.pptx")
my_pres <- read_pptx("../Out/SlideTemplate.pptx")
walk(plts_list, function(i){
my_pres <<- my_pres %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with_gg(value = i )
})
print(my_pres, target = "../Out/AbbyLabMeeting2018.pptx")
=======
rm(list=ls
())
make_list_from_excels <- function(target.dir = "C:/Users/drk8b9/Documents/GitHubRepos/mentoring_data_analysis/Abby/Data/data_dirs/",
reduce.by = 1000) {
tic <- Sys.time()
sub.dirs <- list.files(target.dir)
output.list <- list()
for (i in seq_along(sub.dirs)) {
target.files <- list.files(paste0(target.dir, sub.dirs[i], "/"))
temp.list <- list()
for (j in seq_along(target.files)) {
temp <- readxl::read_xlsx(paste0(target.dir, sub.dirs[i], "/", target.files[j]))
temp <- janitor::clean_names(temp)
# Reduce data by user specified amount
temp <- temp[seq(from = 1, to = nrow(temp), by = reduce.by), ]
#  duplicate the first row of $Condition and $`File Number` for all rows
temp[seq(1, nrow(temp)), "condition"] <- temp[1, "condition"]
temp[seq(1, nrow(temp)), "file_number"] <- temp[1, "file_number"]
# Add a column to help correct time col later
temp$recording <- target.files[j]
temp.list[[(length(temp.list) + 1)]] <- temp
}
output.list[[(length(output.list) + 1)]] <- temp.list
}
toc <- Sys.time()
print(toc - tic)
return(output.list)
}
make_ldf_from_lol <- function(input.list = output.list) {
# Convert list of lists (of dfs) into list of dfs
output.list <- list()
for (i in seq_along(input.list)) {
temp.list <- input.list[[i]]
temp.df <- data.frame()
# Consolidate everything from one exp
for (j in seq_along(temp.list)) {
temp.df <- rbind(temp.df, temp.list[[j]])
}
output.list[[(length(output.list) + 1)]] <- temp.df
}
return(output.list)
}
make_df_from_ldf <- function(
input.list = output.list) {
# Convert a list of dfs into one df
output.df <- data.frame()
for (i in seq_along(input.list)) {
output.df <- rbind(output.df, input.list[[i]])
}
return(output.df)
}
get_cor_over_time <- function(input.df = M[1:100, ],
col.x = "in4",
col.y = "in6",
nbins = 3,
keep.every = 1,
method = "pearson") {
out.vector <- matrix(nrow = nrow(input.df), ncol = 1)
bin.size <- floor(nrow(input.df) / nbins)
bin.start <- 1
for (i in 1:nbins) {
if (i != nbins) {
bin.end <- bin.start + bin.size
} else {
# For the last itteration, lump all the remaining observations into the last bin. This of course can result in the final bin being (2x-1) instead of x.
bin.end <- nrow(input.df)
}
bin.cor <- cor(input.df[seq(from = bin.start, to = bin.end, by = keep.every), col.x],
input.df[seq(from = bin.start, to = bin.end, by = keep.every), col.y],
method = method
)
out.vector[seq(from = bin.start, to = bin.end, by = 1)] <- bin.cor
bin.start <- bin.end
}
return(out.vector)
}
if (update.data.frame == TRUE){
#### Outline ####
# For each dir in Abby/Data/data_dirs/
# For each excel file
# reduce data by a set factor
# return list (of files in exp)
# return list of lists (of returned lists)
output.list0 <- make_list_from_excels(target.dir = "S:/Data_Undergraduate/Data_Abby/Fall2018/data/",
reduce.by = 500)
#output.list0 <- make_list_from_excels(target.dir = "C:/Users/drk8b9/Documents/GitHubRepos/mentoring_data_analysis/Abby/Data/data_dirs/",
#                                  reduce.by = 500)
output.list1 <- make_ldf_from_lol(input.list = output.list0)
output.list2 <- make_df_from_ldf(input.list = output.list1)
M <- output.list2
write_rds(M, "../data/combined_data.rds")
write.csv(M, "../data/combined_data.csv")
} else {
M <- read_rds("../data/combined_data.rds")
}
library(readr) # write_rds, read_rds
library(esquisse) # GUI interface for ggplot2
library(readxl) # Importing xlsx
library(mgcv) # Used to drop low signal/noise data with GAM
library(janitor) # renaming df names
library(tidyverse) # Plotting, Data wrangling
library(cowplot) # plot grid
update.data.frame <- TRUE
use.cor.bins <- 1000
drop.low.signal.noise <- TRUE
>>>>>>> Stashed changes
